{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Llama SEA-LION v3.5 8B R with QLoRA and SageMaker remote decorator\n",
    "\n",
    "This notebook has been modified from [https://github.com/aws-samples/amazon-sagemaker-llm-fine-tuning-remote-decorator/blob/main/llama/llama-3.1-8b-qlora-ddp-remote-decorator_qa.ipynb](https://github.com/aws-samples/amazon-sagemaker-llm-fine-tuning-remote-decorator/blob/main/llama/llama-3.1-8b-qlora-ddp-remote-decorator_qa.ipynb)\n",
    "\n",
    "## Question & Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this demo notebook, we demonstrate how to fine-tune Llama-SEA-LION-v3.5-8B-R using QLoRA, Hugging Face PEFT, and bitsandbytes.\n",
    "\n",
    "We are using SageMaker remote decorator for runinng the fine-tuning job on Amazon SageMaker Training job\n",
    "---\n",
    "\n",
    "JupyterLab Instance Type: ml.t3.medium\n",
    "\n",
    "Python version: 3.11\n",
    "\n",
    "Fine-Tuning:\n",
    "* Instance Type: ml.g5.12xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libriaries, including the Hugging Face libraries, and restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile requirements.txt\n",
    "# transformers==4.51.3\n",
    "# peft==0.15.2\n",
    "# accelerate==1.6.0\n",
    "# bitsandbytes==0.45.5\n",
    "# cloudpickle==3.1.1\n",
    "# datasets==3.5.1\n",
    "# evaluate==0.4.3\n",
    "# huggingface_hub[hf_transfer]\n",
    "# safetensors>=0.5.2\n",
    "# sagemaker==2.244.0\n",
    "# sentencepiece==0.2.0\n",
    "# scikit-learn==1.6.1\n",
    "# tokenizers>=0.21.1\n",
    "# py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "transformers\n",
    "peft\n",
    "accelerate\n",
    "bitsandbytes\n",
    "cloudpickle\n",
    "datasets\n",
    "evaluate\n",
    "huggingface_hub[hf_transfer]\n",
    "safetensors\n",
    "sagemaker\n",
    "sentencepiece\n",
    "scikit-learn\n",
    "tokenizers\n",
    "py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:38:06.851473Z",
     "start_time": "2023-07-20T12:38:04.440644Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.55.4)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.17.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.10.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.47.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.6.2)\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2.251.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (1.7.1)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.21.4)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: huggingface_hub[hf_transfer] in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.34.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft->-r requirements.txt (line 2)) (2.4.1.post100)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 6)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 6)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 6)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->-r requirements.txt (line 8)) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->-r requirements.txt (line 8)) (1.1.8)\n",
      "Requirement already satisfied: hf-transfer>=0.1.4 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->-r requirements.txt (line 8)) (0.1.9)\n",
      "Requirement already satisfied: attrs<26,>=24 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (25.3.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.39.5 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (1.40.17)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (0.115.12)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: graphene<4,>=3 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (3.4.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (4.23.0)\n",
      "Requirement already satisfied: omegaconf<3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (4.3.7)\n",
      "Requirement already satisfied: protobuf<6.32,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (4.25.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (1.0.55)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (1.26.19)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 10)) (0.32.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 12)) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 12)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.20.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (3.23.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (1.1.0)\n",
      "Requirement already satisfied: pyzstd>=0.16.1 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (0.17.0)\n",
      "Requirement already satisfied: pyppmd<1.3.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (1.2.0)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (1.0.6)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 14)) (1.0.3)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.17 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.39.5->sagemaker->-r requirements.txt (line 10)) (1.40.17)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.39.5->sagemaker->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.39.5->sagemaker->-r requirements.txt (line 10)) (0.13.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (3.9.5)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4,>=3->sagemaker->-r requirements.txt (line 10)) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4,>=3->sagemaker->-r requirements.txt (line 10)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/conda/lib/python3.11/site-packages (from graphene<4,>=3->sagemaker->-r requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker->-r requirements.txt (line 10)) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from omegaconf<3,>=2.2->sagemaker->-r requirements.txt (line 10)) (4.9.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (2.11.3)\n",
      "Requirement already satisfied: rich<15.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (14.0.0)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 10)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 10)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker->-r requirements.txt (line 10)) (0.24.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker->-r requirements.txt (line 10)) (0.46.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 6)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->-r requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker->-r requirements.txt (line 10)) (1.7.6.9)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker->-r requirements.txt (line 10)) (0.3.5)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker->-r requirements.txt (line 10)) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker->-r requirements.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (6.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.18.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (0.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker->-r requirements.txt (line 10)) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker->-r requirements.txt (line 10)) (0.1.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (0.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --upgrade\n",
    "%pip install -q -U python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Configuration file path\n",
    "\n",
    "We are setting the directory in which the config.yaml file resides so that remote decorator can make use of the settings through [SageMaker Defaults](https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk).\n",
    "\n",
    "This notebook is using the Hugging Face container for the `us-east-1` region. Make sure you are using the right image for your AWS region, otherwise edit [config.yaml](./config.yaml). Container Images are available [here](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:51.291677Z",
     "start_time": "2023-11-15T09:24:51.282905Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Use .env in case of hidden variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and upload the dataset\n",
    "\n",
    "We are going to load [rajpurkar/squad](https://huggingface.co/datasets/rajpurkar/squad) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook may not work on earlier versions of the datasets library, such as version 3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "datasets.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a816eb392747deb23a24837f0da608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b469fed32c4ac5abaced2775965a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/validation-00000-of-00001.par(…):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c307d980912d430d8e56d68693f3f4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c6c4ba22be4f298877c9119b56f458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"rajpurkar/squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:55.572481Z",
     "start_time": "2023-11-15T09:24:52.575954Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                    answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df = df.iloc[0:1000]\n",
    "df['answer'] = [answer['text'][0] for answer in df['answers']]\n",
    "df = df[['context', 'question', 'answer']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:00.270970Z",
     "start_time": "2023-09-03T00:01:59.205060Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train elements:  900\n",
      "Number of test elements:  100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Number of train elements: \", len(train))\n",
    "print(\"Number of test elements: \", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prompt template and load the dataset with a random sample to try summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:01.435195Z",
     "start_time": "2023-09-03T00:02:01.429794Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# custom instruct prompt start\n",
    "prompt_template = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>Context:{{context}}  {{question}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>{{answer}}<|end_of_text|><|eot_id|>\"\"\"\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = prompt_template.format(context=sample[\"context\"],\n",
    "                                            question=sample[\"question\"],\n",
    "                                            answer=sample[\"answer\"])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Hugging Face Trainer class to fine-tune the model. Define the hyperparameters we want to use. We also create a DataCollator that will take care of padding our inputs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:10.364459Z",
     "start_time": "2023-09-03T00:02:09.672705Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669d351334d940919003f9f43a1bbcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Context:In 2001, she became the first African-American woman and second woman songwriter to win the Pop Songwriter of the Year award at the American Society of Composers, Authors, and Publishers Pop Music Awards. Beyoncé was the third woman to have writing credits on three number one songs (\"Irreplaceable\", \"Grillz\" and \"Check on It\") in the same year, after Carole King in 1971 and Mariah Carey in 1991. She is tied with American songwriter Diane Warren at third with nine songwriting credits on number-one singles. (The latter wrote her 9/11-motivated song \"I Was Here\" for 4.) In May 2011, Billboard magazine listed Beyoncé at number 17 on their list of the \"Top 20 Hot 100 Songwriters\", for having co-written eight singles that hit number one on the Billboard Hot 100 chart. She was one of only three women on that list.  Pop Songwriter of the Year award in 2001 was awarded to whom?<|eot_id|><|start_header_id|>assistant<|end_header_id|>Beyoncé<|end_of_text|><|eot_id|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e61257982e941c0a73329790a025975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(template_dataset, remove_columns=list(dataset[\"train\"].features))\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(template_dataset, remove_columns=list(dataset[\"test\"].features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function for initializing the distribution across multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "\n",
    "def init_distributed():\n",
    "    # Initialize the process group\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=\"nccl\",  # Use \"gloo\" backend for CPU\n",
    "        timeout=datetime.timedelta(seconds=5400),\n",
    "    )\n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    torch.cuda.set_device(local_rank)\n",
    "\n",
    "    return local_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function for model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "def download_model(model_name):\n",
    "    print(\"Downloading model \", model_name)\n",
    "\n",
    "    os.makedirs(\"/tmp/tmp_folder\", exist_ok=True)\n",
    "\n",
    "    snapshot_download(repo_id=model_name, local_dir=\"/tmp/tmp_folder\")\n",
    "\n",
    "    print(f\"Model {model_name} downloaded under /tmp/tmp_folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model, we need to convert our inputs (text) to token IDs. This is done by a Hugging Face Transformers Tokenizer. In addition to Lora, we will use bitsanbytes 4-bit precision to quantize out frozen LLM to 4-bit and attach LoRA adapters on it.\n",
    "\n",
    "Define the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model_id = \"aisingapore/Llama-SEA-LION-v3.5-8B-R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "SchemaVersion: \"1.0\"\n",
    "SageMaker:\n",
    "  PythonSDK:\n",
    "    Modules:\n",
    "      RemoteFunction:\n",
    "        Dependencies: ./requirements.txt\n",
    "        ImageUri: \"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.5.1-gpu-py311-cu124-ubuntu22.04-sagemaker\"\n",
    "        InstanceType: ml.g5.12xlarge\n",
    "        IncludeLocalWorkDir: true\n",
    "        PreExecutionCommands:\n",
    "          - \"export NCCL_P2P_DISABLE=1\"\n",
    "          - \"export HF_HUB_ENABLE_HF_TRANSFER=1\"\n",
    "        CustomFileFilter:\n",
    "          IgnoreNamePatterns:\n",
    "            - \"data/*\"\n",
    "            - \"models/*\"\n",
    "            - \"*.ipynb\"\n",
    "            - \"*.csv\"\n",
    "            - \"*.md\"\n",
    "            - \"__pycache__\"\n",
    "        # RoleArn: RoleArn required if you are running the notebooks from a local IDE\n",
    "  Model:\n",
    "    EnableNetworkIsolation: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:21.382486Z",
     "start_time": "2023-09-03T00:02:20.962208Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.PreExecutionCommands\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.InstanceType\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "import datetime\n",
    "import os\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sagemaker.remote_function import remote\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed\n",
    "import transformers\n",
    "\n",
    "# Start training\n",
    "@remote(\n",
    "    keep_alive_period_in_seconds=0, #Warm-pool instance. Put 0 for avoiding additional costs\n",
    "    volume_size=100,\n",
    "    job_name_prefix=f\"train-{model_id.split('/')[-1].replace('.', '-')}\", \n",
    "    use_torchrun=True, # for distribution\n",
    ")\n",
    "def train_fn(\n",
    "    model_name,             # Name or path of the base model to fine-tune\n",
    "    train_ds,               # Training dataset\n",
    "    test_ds=None,           # Optional test/validation dataset\n",
    "    torch_dtype=torch.bfloat16,  # Precision type for training\n",
    "    lora_r=8,               # LoRA rank - controls capacity of adaptations\n",
    "    lora_alpha=16,          # LoRA alpha - scales the adaptations\n",
    "    lora_dropout=0.1,       # Dropout probability for LoRA layers\n",
    "    per_device_train_batch_size=8,  # Batch size for training\n",
    "    per_device_eval_batch_size=8,   # Batch size for evaluation\n",
    "    gradient_accumulation_steps=1,  # Number of steps to accumulate gradients\n",
    "    learning_rate=2e-4,     # Learning rate for training\n",
    "    num_train_epochs=1,     # Number of training epochs\n",
    "    fsdp=\"\",                # Fully Sharded Data Parallel configuration\n",
    "    fsdp_config=None,       # Additional FSDP configurations\n",
    "    gradient_checkpointing=False,  # Whether to use gradient checkpointing\n",
    "    merge_weights=False,    # Whether to merge LoRA weights with base model\n",
    "    seed=42,                # Random seed for reproducibility\n",
    "    token=None              # HuggingFace token for model access\n",
    "):\n",
    "    # Initialize distributed training if multiple GPUs are available\n",
    "    if torch.cuda.is_available() and (torch.cuda.device_count() > 1 or int(os.environ.get(\"SM_HOST_COUNT\", 1)) > 1):\n",
    "        # Call this function at the beginning of your script\n",
    "        local_rank = init_distributed()\n",
    "\n",
    "        # Now you can use distributed functionalities\n",
    "        torch.distributed.barrier(device_ids=[local_rank])\n",
    "\n",
    "    # Enable HuggingFace transfer for model downloading\n",
    "    os.environ.update({\"HF_HUB_ENABLE_HF_TRANSFER\": \"1\"})\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # Set up HuggingFace token if provided\n",
    "    if token is not None:\n",
    "        os.environ.update({\"HF_TOKEN\": token})\n",
    "        accelerator.wait_for_everyone()\n",
    "\n",
    "    # Download model based on training setup (single or multi-node)\n",
    "    if int(os.environ.get(\"SM_HOST_COUNT\", 1)) == 1:\n",
    "        if accelerator.is_main_process:\n",
    "            download_model(model_name)\n",
    "    else:\n",
    "        download_model(model_name)\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    model_name = \"/tmp/tmp_folder\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Set Tokenizer pad Token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        # tokenize and chunk dataset\n",
    "        lm_train_dataset = train_ds.map(\n",
    "            lambda sample: tokenizer(sample[\"text\"]), remove_columns=list(train_ds.features)\n",
    "        )\n",
    "\n",
    "        print(f\"Total number of train samples: {len(lm_train_dataset)}\")\n",
    "\n",
    "        if test_ds is not None:\n",
    "            lm_test_dataset = test_ds.map(\n",
    "                lambda sample: tokenizer(sample[\"text\"]), remove_columns=list(test_ds.features)\n",
    "            )\n",
    "\n",
    "            print(f\"Total number of test samples: {len(lm_test_dataset)}\")\n",
    "        else:\n",
    "            lm_test_dataset = None\n",
    "\n",
    "    # Configure model settings for bfloat16 precision\n",
    "    # Setup flash_attention_2 for memory-efficient attention computation\n",
    "    if torch_dtype == torch.bfloat16:\n",
    "        print(\"flash_attention_2 init\")\n",
    "\n",
    "        model_configs = {\n",
    "            \"attn_implementation\": \"flash_attention_2\",\n",
    "            \"torch_dtype\": torch_dtype,\n",
    "        }\n",
    "    else:\n",
    "        model_configs = dict()\n",
    "\n",
    "    # Configure training settings based on FSDP usage\n",
    "    # Set up trainer configurations for FSDP or standard training\n",
    "    if fsdp != \"\" and fsdp_config is not None:\n",
    "        print(\"Configurations for FSDP\")\n",
    "\n",
    "        bnb_config_params = {\n",
    "            \"bnb_4bit_quant_storage\": torch_dtype\n",
    "        }\n",
    "\n",
    "        trainer_configs = {\n",
    "            \"fsdp\": fsdp,\n",
    "            \"fsdp_config\": fsdp_config,\n",
    "            \"gradient_checkpointing_kwargs\": {\n",
    "                \"use_reentrant\": False\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        bnb_config_params = dict()\n",
    "        trainer_configs = {\n",
    "            \"gradient_checkpointing\": gradient_checkpointing, # Enable in case of DDP\n",
    "        }\n",
    "\n",
    "    # Enable Quantization\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch_dtype,\n",
    "        **bnb_config_params\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config,\n",
    "        use_cache=not gradient_checkpointing,\n",
    "        cache_dir=\"/tmp/.cache\",\n",
    "        **model_configs\n",
    "    )\n",
    "\n",
    "    # Configure gradient checkpointing based on FSDP usage\n",
    "    if fsdp == \"\" and fsdp_config is None:\n",
    "        print(\"Prepare model for quantization\")\n",
    "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=gradient_checkpointing)\n",
    "\n",
    "        if gradient_checkpointing:\n",
    "            print(\"gradient_checkpointing enabled\")\n",
    "            model.gradient_checkpointing_enable()\n",
    "    else:\n",
    "        if gradient_checkpointing:\n",
    "            print(\"gradient_checkpointing enabled\")\n",
    "            model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=\"all-linear\",\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=lm_train_dataset,\n",
    "        eval_dataset=lm_test_dataset if lm_test_dataset is not None else None,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            logging_strategy=\"steps\",\n",
    "            logging_steps=1,\n",
    "            log_on_each_node=False,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            bf16=(\n",
    "                True if torch_dtype == torch.bfloat16 else False\n",
    "            ),  # Enable mixed-precision training\n",
    "            tf32=False,\n",
    "            ddp_find_unused_parameters=False,\n",
    "            save_strategy=\"no\",\n",
    "            output_dir=\"outputs\",\n",
    "            **trainer_configs\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    if trainer.accelerator.is_main_process:\n",
    "        trainer.model.print_trainable_parameters()\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    if trainer.is_fsdp_enabled:\n",
    "        trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n",
    "\n",
    "    if merge_weights:\n",
    "        output_dir = \"/tmp/model\"\n",
    "\n",
    "        # merge adapter weights with base model and save\n",
    "        # save int 4 model\n",
    "        trainer.model.save_pretrained(output_dir, safe_serialization=False)\n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            # clear memory\n",
    "            del model\n",
    "            del trainer\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # load PEFT model\n",
    "            model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "                output_dir,\n",
    "                torch_dtype=torch.float16,\n",
    "                low_cpu_mem_usage=True,\n",
    "                trust_remote_code=True,\n",
    "                use_cache=True,\n",
    "                cache_dir=\"/tmp/.cache\",\n",
    "            )\n",
    "\n",
    "            # Merge LoRA and base model and save\n",
    "            model = model.merge_and_unload()\n",
    "            model.save_pretrained(\n",
    "                os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"),\n",
    "                safe_serialization=True,\n",
    "                max_shard_size=\"2GB\"\n",
    "            )\n",
    "    else:\n",
    "        trainer.model.save_pretrained(\n",
    "            os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"),\n",
    "            safe_serialization=True\n",
    "        )\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"))\n",
    "\n",
    "    accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:31:30,792 sagemaker.remote_function INFO     Serializing function code to s3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/function\n",
      "2025-08-26 03:31:30,883 sagemaker.remote_function INFO     Serializing function arguments to s3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/arguments\n",
      "2025-08-26 03:31:31,158 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmph8rjn0t1/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2025-08-26 03:31:31,160 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmph8rjn0t1/temp_workspace/sagemaker_remote_function_workspace/requirements.txt'\n",
      "2025-08-26 03:31:31,160 sagemaker.remote_function INFO     Generated pre-execution script from commands to '/tmp/tmph8rjn0t1/temp_workspace/sagemaker_remote_function_workspace/pre_exec.sh'\n",
      "2025-08-26 03:31:31,174 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmph8rjn0t1/workspace.zip'\n",
      "2025-08-26 03:31:31,204 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/sm_rf_user_ws/workspace.zip'\n",
      "2025-08-26 03:31:31,205 sagemaker.remote_function INFO     Creating job: train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:31:31 Starting - Starting the training job\n",
      "2025-08-26 03:31:31 Pending - Training job waiting for capacity............\n",
      "2025-08-26 03:33:19 Pending - Preparing the instances for training...\n",
      "2025-08-26 03:34:03 Downloading - Downloading the training image...\u001b[34m{'loss': 1.3548, 'grad_norm': 1.0879859924316406, 'learning_rate': 0.0001801169590643275, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4307, 'grad_norm': 1.0881348848342896, 'learning_rate': 0.00017894736842105264, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5761, 'grad_norm': 1.0529218912124634, 'learning_rate': 0.00017777777777777779, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7304, 'grad_norm': 1.1258245706558228, 'learning_rate': 0.00017660818713450294, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2001, 'grad_norm': 1.187904715538025, 'learning_rate': 0.00017543859649122806, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3064, 'grad_norm': 1.344528317451477, 'learning_rate': 0.00017426900584795323, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2368, 'grad_norm': 1.1745365858078003, 'learning_rate': 0.00017309941520467836, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4071, 'grad_norm': 0.9774373173713684, 'learning_rate': 0.00017192982456140353, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2399, 'grad_norm': 0.8425534963607788, 'learning_rate': 0.00017076023391812865, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6117, 'grad_norm': 1.1544235944747925, 'learning_rate': 0.0001695906432748538, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3885, 'grad_norm': 1.1793104410171509, 'learning_rate': 0.00016842105263157895, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1581, 'grad_norm': 1.2392017841339111, 'learning_rate': 0.0001672514619883041, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1851, 'grad_norm': 1.41336190700531, 'learning_rate': 0.00016608187134502925, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0821, 'grad_norm': 1.4665420055389404, 'learning_rate': 0.0001649122807017544, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2002, 'grad_norm': 1.1818736791610718, 'learning_rate': 0.00016374269005847952, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9108, 'grad_norm': 1.2578866481781006, 'learning_rate': 0.0001625730994152047, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0825, 'grad_norm': 1.1821688413619995, 'learning_rate': 0.00016140350877192982, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0309, 'grad_norm': 1.7856228351593018, 'learning_rate': 0.000160233918128655, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0601, 'grad_norm': 1.3942278623580933, 'learning_rate': 0.00015906432748538012, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0505, 'grad_norm': 1.4822722673416138, 'learning_rate': 0.00015789473684210527, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m{'loss': 1.028, 'grad_norm': 1.405591607093811, 'learning_rate': 0.00015672514619883041, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.923, 'grad_norm': 1.548134207725525, 'learning_rate': 0.00015555555555555556, 'epoch': 0.69}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7903, 'grad_norm': 1.2061372995376587, 'learning_rate': 0.0001543859649122807, 'epoch': 0.71}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8524, 'grad_norm': 1.6416356563568115, 'learning_rate': 0.00015321637426900586, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8805, 'grad_norm': 2.2192299365997314, 'learning_rate': 0.00015204678362573098, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m{'loss': 0.528, 'grad_norm': 2.0233583450317383, 'learning_rate': 0.00015087719298245616, 'epoch': 0.76}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8846, 'grad_norm': 1.3483130931854248, 'learning_rate': 0.00014970760233918128, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m{'loss': 0.602, 'grad_norm': 1.413956642150879, 'learning_rate': 0.00014853801169590643, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7405, 'grad_norm': 1.3233028650283813, 'learning_rate': 0.00014736842105263158, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6267, 'grad_norm': 1.3834279775619507, 'learning_rate': 0.00014619883040935673, 'epoch': 0.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7879, 'grad_norm': 1.3940497636795044, 'learning_rate': 0.00014502923976608188, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7287, 'grad_norm': 1.313528299331665, 'learning_rate': 0.00014385964912280703, 'epoch': 0.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6343, 'grad_norm': 1.190386176109314, 'learning_rate': 0.00014269005847953217, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6064, 'grad_norm': 1.129352331161499, 'learning_rate': 0.00014152046783625732, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8835, 'grad_norm': 1.394842267036438, 'learning_rate': 0.00014035087719298245, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5986, 'grad_norm': 1.7219287157058716, 'learning_rate': 0.00013918128654970762, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4697, 'grad_norm': 1.3503749370574951, 'learning_rate': 0.00013801169590643274, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5329, 'grad_norm': 1.6219168901443481, 'learning_rate': 0.0001368421052631579, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5691, 'grad_norm': 1.2054864168167114, 'learning_rate': 0.00013567251461988304, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m{'loss': 0.926, 'grad_norm': 1.7102311849594116, 'learning_rate': 0.0001345029239766082, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2713, 'grad_norm': 1.2288970947265625, 'learning_rate': 0.00013333333333333334, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2717, 'grad_norm': 1.1948944330215454, 'learning_rate': 0.0001321637426900585, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4705, 'grad_norm': 1.5020900964736938, 'learning_rate': 0.00013099415204678364, 'epoch': 1.05}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5889, 'grad_norm': 1.2514207363128662, 'learning_rate': 0.0001298245614035088, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3223, 'grad_norm': 1.1955546140670776, 'learning_rate': 0.0001286549707602339, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3438, 'grad_norm': 1.6365492343902588, 'learning_rate': 0.00012748538011695908, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m{'loss': 0.463, 'grad_norm': 1.5157947540283203, 'learning_rate': 0.0001263157894736842, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5677, 'grad_norm': 1.9013938903808594, 'learning_rate': 0.00012514619883040936, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5162, 'grad_norm': 1.8792083263397217, 'learning_rate': 0.0001239766081871345, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3557, 'grad_norm': 1.3102256059646606, 'learning_rate': 0.00012280701754385965, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4898, 'grad_norm': 1.333552360534668, 'learning_rate': 0.00012163742690058479, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5596, 'grad_norm': 1.3377151489257812, 'learning_rate': 0.00012046783625730995, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3436, 'grad_norm': 1.142151117324829, 'learning_rate': 0.00011929824561403509, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3809, 'grad_norm': 1.0319833755493164, 'learning_rate': 0.00011812865497076025, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4118, 'grad_norm': 1.3045884370803833, 'learning_rate': 0.00011695906432748539, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2783, 'grad_norm': 1.092420220375061, 'learning_rate': 0.00011578947368421053, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2182, 'grad_norm': 1.08302903175354, 'learning_rate': 0.00011461988304093567, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4218, 'grad_norm': 1.861240029335022, 'learning_rate': 0.00011345029239766083, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3585, 'grad_norm': 1.3662430047988892, 'learning_rate': 0.00011228070175438597, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3506, 'grad_norm': 1.9133542776107788, 'learning_rate': 0.00011111111111111112, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7034, 'grad_norm': 2.3206536769866943, 'learning_rate': 0.00010994152046783625, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m{'loss': 0.286, 'grad_norm': 0.957234799861908, 'learning_rate': 0.00010877192982456141, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2373, 'grad_norm': 0.8674737215042114, 'learning_rate': 0.00010760233918128655, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6169, 'grad_norm': 1.1867200136184692, 'learning_rate': 0.00010643274853801171, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2945, 'grad_norm': 1.0151112079620361, 'learning_rate': 0.00010526315789473685, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2123, 'grad_norm': 0.8433195948600769, 'learning_rate': 0.000104093567251462, 'epoch': 1.46}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2316, 'grad_norm': 0.9100402593612671, 'learning_rate': 0.00010292397660818713, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2003, 'grad_norm': 0.9291003346443176, 'learning_rate': 0.0001017543859649123, 'epoch': 1.5}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2575, 'grad_norm': 1.11607027053833, 'learning_rate': 0.00010058479532163743, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1537, 'grad_norm': 1.0068942308425903, 'learning_rate': 9.941520467836257e-05, 'epoch': 1.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2697, 'grad_norm': 1.6477173566818237, 'learning_rate': 9.824561403508771e-05, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2967, 'grad_norm': 1.9414784908294678, 'learning_rate': 9.707602339181286e-05, 'epoch': 1.57}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2986, 'grad_norm': 1.7249674797058105, 'learning_rate': 9.590643274853801e-05, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1871, 'grad_norm': 1.1996026039123535, 'learning_rate': 9.473684210526316e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4129, 'grad_norm': 1.5744649171829224, 'learning_rate': 9.35672514619883e-05, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2809, 'grad_norm': 1.0619899034500122, 'learning_rate': 9.239766081871345e-05, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2387, 'grad_norm': 1.0607854127883911, 'learning_rate': 9.12280701754386e-05, 'epoch': 1.65}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2035, 'grad_norm': 0.8924694657325745, 'learning_rate': 9.005847953216374e-05, 'epoch': 1.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2572, 'grad_norm': 0.9111214280128479, 'learning_rate': 8.888888888888889e-05, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3469, 'grad_norm': 0.9310984015464783, 'learning_rate': 8.771929824561403e-05, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2424, 'grad_norm': 1.0996241569519043, 'learning_rate': 8.654970760233918e-05, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2767, 'grad_norm': 1.13241708278656, 'learning_rate': 8.538011695906433e-05, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3459, 'grad_norm': 1.064100742340088, 'learning_rate': 8.421052631578948e-05, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2559, 'grad_norm': 1.076511263847351, 'learning_rate': 8.304093567251462e-05, 'epoch': 1.78}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1934, 'grad_norm': 1.2648087739944458, 'learning_rate': 8.187134502923976e-05, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m#015  1%|          | 1/171 [00:02<07:24,  2.62s/it]#015                                               #015#015  1%|          | 1/171 [00:02<07:24,  2.62s/it]#015  1%|          | 2/171 [00:05<07:33,  2.68s/it]#015                                               #015#015  1%|          | 2/171 [00:05<07:33,  2.68s/it]#015  2%|▏         | 3/171 [00:07<06:50,  2.44s/it]#015                                               #015#015  2%|▏         | 3/171 [00:07<06:50,  2.44s/it]#015  2%|▏         | 4/171 [00:09<06:41,  2.40s/it]#015                                               #015#015  2%|▏         | 4/171 [00:09<06:41,  2.40s/it]#015  3%|▎         | 5/171 [00:12<07:08,  2.58s/it]#015                                               #015#015  3%|▎         | 5/171 [00:12<07:08,  2.58s/it]#015  4%|▎         | 6/171 [00:15<07:04,  2.57s/it]#015                                               #015#015  4%|▎         | 6/171 [00:15<07:04,  2.57s/it]#015  4%|▍         | 7/171 [00:17<06:41,  2.45s/it]#015                                               #015#015  4%|▍         | 7/171 [00:17<06:41,  2.45s/it]#015  5%|▍         | 8/171 [00:19<06:38,  2.44s/it]#015                                               #015#015  5%|▍         | 8/171 [00:19<06:38,  2.44s/it]#015  5%|▌         | 9/171 [00:22<06:17,  2.33s/it]#015                                               #015#015  5%|▌         | 9/171 [00:22<06:17,  2.33s/it]#015  6%|▌         | 10/171 [00:24<06:19,  2.36s/it]#015                                                #015#015  6%|▌         | 10/171 [00:24<06:19,  2.36s/it]#015  6%|▋         | 11/171 [00:26<06:23,  2.40s/it]#015                                                #015#015  6%|▋         | 11/171 [00:26<06:23,  2.40s/it]#015  7%|▋         | 12/171 [00:29<06:23,  2.41s/it]#015                                                #015#015  7%|▋         | 12/171 [00:29<06:23,  2.41s/it]#015  8%|▊         | 13/171 [00:31<06:03,  2.30s/it]#015                                                #015#015  8%|▊         | 13/171 [00:31<06:03,  2.30s/it]#015  8%|▊         | 14/171 [00:33<06:12,  2.38s/it]#015                                                #015#015  8%|▊         | 14/171 [00:33<06:12,  2.38s/it]#015  9%|▉         | 15/171 [00:35<05:53,  2.27s/it]#015                                                #015#015  9%|▉         | 15/171 [00:35<05:53,  2.27s/it]#015  9%|▉         | 16/171 [00:38<06:18,  2.44s/it]#015                                                #015#015  9%|▉         | 16/171 [00:38<06:18,  2.44s/it]#015 10%|▉         | 17/171 [00:41<06:11,  2.41s/it]#015                                                #015#015 10%|▉         | 17/171 [00:41<06:11,  2.41s/it]#015 11%|█         | 18/171 [00:43<06:21,  2.49s/it]#015                                                #015#015 11%|█         | 18/171 [00:43<06:21,  2.49s/it]#015 11%|█         | 19/171 [00:46<06:13,  2.46s/it]#015                                                #015#015 11%|█         | 19/171 [00:46<06:13,  2.46s/it]#015 12%|█▏        | 20/171 [00:48<06:23,  2.54s/it]#015                                                #015#015 12%|█▏        | 20/171 [00:48<06:23,  2.54s/it]#015 12%|█▏        | 21/171 [00:51<06:27,  2.58s/it]#015                                                #015#015 12%|█▏        | 21/171 [00:51<06:27,  2.58s/it]#015 13%|█▎        | 22/171 [00:53<06:15,  2.52s/it]#015                                                #015#015 13%|█▎        | 22/171 [00:53<06:15,  2.52s/it]#015 13%|█▎        | 23/171 [00:56<06:13,  2.52s/it]#015                                                #015#015 13%|█▎        | 23/171 [00:56<06:13,  2.52s/it]#015 14%|█▍        | 24/171 [00:59<06:30,  2.66s/it]#015                                                #015#015 14%|█▍        | 24/171 [00:59<06:30,  2.66s/it]#015 15%|█▍        | 25/171 [01:01<06:08,  2.52s/it]#015                                                #015#015 15%|█▍        | 25/171 [01:01<06:08,  2.52s/it]#015 15%|█▌        | 26/171 [01:03<05:45,  2.38s/it]#015                                                #015#015 15%|█▌        | 26/171 [01:03<05:45,  2.38s/it]#015 16%|█▌        | 27/171 [01:05<05:31,  2.30s/it]#015                                                #015#015 16%|█▌        | 27/171 [01:05<05:31,  2.30s/it]#015 16%|█▋        | 28/171 [01:07<05:17,  2.22s/it]#015                                                #015#015 16%|█▋        | 28/171 [01:07<05:17,  2.22s/it]#015 17%|█▋        | 29/171 [01:10<05:21,  2.26s/it]#015                                                #015#015 17%|█▋        | 29/171 [01:10<05:21,  2.26s/it]#015 18%|█▊        | 30/171 [01:12<05:29,  2.34s/it]#015                                                #015#015 18%|█▊        | 30/171 [01:12<05:29,  2.34s/it]#015 18%|█▊        | 31/171 [01:14<05:09,  2.21s/it]#015                                                #015#015 18%|█▊        | 31/171 [01:14<05:09,  2.21s/it]#015 19%|█▊        | 32/171 [01:16<05:06,  2.20s/it]#015                                                #015#015 19%|█▊        | 32/171 [01:16<05:06,  2.20s/it]#015 19%|█▉        | 33/171 [01:19<05:02,  2.19s/it]#015                                                #015#015 19%|█▉        | 33/171 [01:19<05:02,  2.19s/it]#015 20%|█▉        | 34/171 [01:21<05:13,  2.29s/it]#015                                                #015#015 20%|█▉        | 34/171 [01:21<05:13,  2.29s/it]#015 20%|██        | 35/171 [01:24<05:22,  2.37s/it]#015                                                #015#015 20%|██        | 35/171 [01:24<05:22,  2.37s/it]#015 21%|██        | 36/171 [01:26<05:26,  2.42s/it]#015                                                #015#015 21%|██        | 36/171 [01:26<05:26,  2.42s/it]#015 22%|██▏       | 37/171 [01:29<05:35,  2.50s/it]#015                                                #015#015 22%|██▏       | 37/171 [01:29<05:35,  2.50s/it]#015 22%|██▏       | 38/171 [01:32<05:41,  2.57s/it]#015                                                #015#015 22%|██▏       | 38/171 [01:32<05:41,  2.57s/it]#015 23%|██▎       | 39/171 [01:34<05:35,  2.54s/it]#015                                                #015#015 23%|██▎       | 39/171 [01:34<05:35,  2.54s/it]#015 23%|██▎       | 40/171 [01:37<06:02,  2.77s/it]#015                                                #015#015 23%|██▎       | 40/171 [01:37<06:02,  2.77s/it]#015 24%|██▍       | 41/171 [01:40<05:43,  2.64s/it]#015                                                #015#015 24%|██▍       | 41/171 [01:40<05:43,  2.64s/it]#015 25%|██▍       | 42/171 [01:42<05:27,  2.54s/it]#015                                                #015#015 25%|██▍       | 42/171 [01:42<05:27,  2.54s/it]#015 25%|██▌       | 43/171 [01:44<05:09,  2.42s/it]#015                                                #015#015 25%|██▌       | 43/171 [01:44<05:09,  2.42s/it]#015 26%|██▌       | 44/171 [01:47<05:18,  2.50s/it]#015                                                #015#015 26%|██▌       | 44/171 [01:47<05:18,  2.50s/it]#015 26%|██▋       | 45/171 [01:49<05:07,  2.44s/it]#015                                                #015#015 26%|██▋       | 45/171 [01:49<05:07,  2.44s/it]#015 27%|██▋       | 46/171 [01:52<05:05,  2.44s/it]#015                                                #015#015 27%|██▋       | 46/171 [01:52<05:05,  2.44s/it]#015 27%|██▋       | 47/171 [01:54<04:47,  2.32s/it]#015                                                #015#015 27%|██▋       | 47/171 [01:54<04:47,  2.32s/it]#015 28%|██▊       | 48/171 [01:56<04:59,  2.43s/it]#015                                                #015#015 28%|██▊       | 48/171 [01:56<04:59,  2.43s/it]#015 29%|██▊       | 49/171 [01:59<04:48,  2.36s/it]#015                                                #015#015 29%|██▊       | 49/171 [01:59<04:48,  2.36s/it]#015 29%|██▉       | 50/171 [02:01<04:57,  2.46s/it]#015                                                #015#015 29%|██▉       | 50/171 [02:01<04:57,  2.46s/it]#015 30%|██▉       | 51/171 [02:04<04:57,  2.48s/it]#015                                                #015#015 30%|██▉       | 51/171 [02:04<04:57,  2.48s/it]#015 30%|███       | 52/171 [02:06<04:43,  2.38s/it]#015                                                #015#015 30%|███       | 52/171 [02:06<04:43,  2.38s/it]#015 31%|███       | 53/171 [02:08<04:47,  2.43s/it]#015                                                #015#015 31%|███       | 53/171 [02:08<04:47,  2.43s/it]#015 32%|███▏      | 54/171 [02:10<04:28,  2.29s/it]#015                                                #015#015 32%|███▏      | 54/171 [02:10<04:28,  2.29s/it]#015 32%|███▏      | 55/171 [02:13<04:35,  2.37s/it]#015                                                #015#015 32%|███▏      | 55/171 [02:13<04:35,  2.37s/it]#015 33%|███▎      | 56/171 [02:15<04:35,  2.40s/it]#015                                                #015#015 33%|███▎      | 56/171 [02:15<04:35,  2.40s/it]#015 33%|███▎      | 57/171 [02:17<03:49,  2.01s/it]#015                                                #015#015 33%|███▎      | 57/171 [02:17<03:49,  2.01s/it]#015 34%|███▍      | 58/171 [02:19<04:05,  2.17s/it]#015                                                #015#015 34%|███▍      | 58/171 [02:19<04:05,  2.17s/it]#015 35%|███▍      | 59/171 [02:21<04:07,  2.21s/it]#015                                                #015#015 35%|███▍      | 59/171 [02:21<04:07,  2.21s/it]#015 35%|███▌      | 60/171 [02:24<04:31,  2.45s/it]#015                                                #015#015 35%|███▌      | 60/171 [02:24<04:31,  2.45s/it]#015 36%|███▌      | 61/171 [02:26<04:16,  2.34s/it]#015                                                #015#015 36%|███▌      | 61/171 [02:26<04:16,  2.34s/it]#015 36%|███▋      | 62/171 [02:28<04:06,  2.26s/it]#015                                                #015#015 36%|███▋      | 62/171 [02:28<04:06,  2.26s/it]#015 37%|███▋      | 63/171 [02:31<03:56,  2.19s/it]#015                                                #015#015 37%|███▋      | 63/171 [02:31<03:56,  2.19s/it]#015 37%|███▋      | 64/171 [02:33<04:00,  2.24s/it]#015                                                #015#015 37%|███▋      | 64/171 [02:33<04:00,  2.24s/it]#015 38%|███▊      | 65/171 [02:35<03:54,  2.21s/it]#015                                                #015#015 38%|███▊      | 65/171 [02:35<03:54,  2.21s/it]#015 39%|███▊      | 66/171 [02:37<03:50,  2.19s/it]#015                                                #015#015 39%|███▊      | 66/171 [02:37<03:50,  2.19s/it]#015 39%|███▉      | 67/171 [02:40<04:10,  2.41s/it]#015                                                #015#015 39%|███▉      | 67/171 [02:40<04:10,  2.41s/it]#015 40%|███▉      | 68/171 [02:42<04:04,  2.37s/it]#015                                                #015#015 40%|███▉      | 68/171 [02:42<04:04,  2.37s/it]#015 40%|████      | 69/171 [02:45<04:02,  2.38s/it]#015                                                #015#015 40%|████      | 69/171 [02:45<04:02,  2.38s/it]#015 41%|████      | 70/171 [02:48<04:16,  2.54s/it]#015                                                #015#015 41%|████      | 70/171 [02:48<04:16,  2.54s/it]#015 42%|████▏     | 71/171 [02:50<04:00,  2.40s/it]#015                                                #015#015 42%|████▏     | 71/171 [02:50<04:00,  2.40s/it]#015 42%|████▏     | 72/171 [02:52<03:46,  2.29s/it]#015                                                #015#015 42%|████▏     | 72/171 [02:52<03:46,  2.29s/it]#015 43%|████▎     | 73/171 [02:55<04:02,  2.48s/it]#015                                                #015#015 43%|████▎     | 73/171 [02:55<04:02,  2.48s/it]#015 43%|████▎     | 74/171 [02:57<03:54,  2.42s/it]#015                                                #015#015 43%|████▎     | 74/171 [02:57<03:54,  2.42s/it]#015 44%|████▍     | 75/171 [03:00<03:56,  2.46s/it]#015                                                #015#015 44%|████▍     | 75/171 [03:00<03:56,  2.46s/it]#015 44%|████▍     | 76/171 [03:02<03:46,  2.39s/it]#015                                                #015#015 44%|████▍     | 76/171 [03:02<03:46,  2.39s/it]#015 45%|████▌     | 77/171 [03:05<04:00,  2.56s/it]#015                                                #015#015 45%|████▌     | 77/171 [03:05<04:00,  2.56s/it]#015 46%|████▌     | 78/171 [03:07<03:48,  2.46s/it]#015                                                #015#015 46%|████▌     | 78/171 [03:07<03:48,  2.46s/it]#015 46%|████▌     | 79/171 [03:09<03:42,  2.42s/it]#015                                                #015#015 46%|████▌     | 79/171 [03:09<03:42,  2.42s/it]#015 47%|████▋     | 80/171 [03:12<03:48,  2.51s/it]#015                                                #015#015 47%|████▋     | 80/171 [03:12<03:48,  2.51s/it]#015 47%|████▋     | 81/171 [03:14<03:40,  2.45s/it]#015                                                #015#015 47%|████▋     | 81/171 [03:14<03:40,  2.45s/it]#015 48%|████▊     | 82/171 [03:16<03:22,  2.27s/it]#015                                                #015#015 48%|████▊     | 82/171 [03:16<03:22,  2.27s/it]#015 49%|████▊     | 83/171 [03:18<03:17,  2.24s/it]#015                                                #015#015 49%|████▊     | 83/171 [03:18<03:17,  2.24s/it]#015 49%|████▉     | 84/171 [03:20<03:12,  2.22s/it]#015                                                #015#015 49%|████▉     | 84/171 [03:20<03:12,  2.22s/it]#015 50%|████▉     | 85/171 [03:23<03:10,  2.21s/it]#015                                                #015#015 50%|████▉     | 85/171 [03:23<03:10,  2.21s/it]#015 50%|█████     | 86/171 [03:25<03:08,  2.22s/it]#015                                                #015#015 50%|█████     | 86/171 [03:25<03:08,  2.22s/it]#015 51%|█████     | 87/171 [03:27<03:10,  2.26s/it]#015                                                #015#015 51%|█████     | 87/171 [03:27<03:10,  2.26s/it]#015 51%|█████▏    | 88/171 [03:30<03:26,  2.49s/it]#015                                                #015#015 51%|█████▏    | 88/171 [03:30<03:26,  2.49s/it]#015 52%|█████▏    | 89/171 [03:33<03:29,  2.56s/it]#015                                                #015#015 52%|█████▏    | 89/171 [03:33<03:29,  2.56s/it]#015 53%|█████▎    | 90/171 [03:35<03:25,  2.53s/it]#015                                                #015#015 53%|█████▎    | 90/171 [03:36<03:25,  2.53s/it]#015 53%|█████▎    | 91/171 [03:38<03:26,  2.59s/it]#015                                                #015#015 53%|█████▎    | 91/171 [03:38<03:26,  2.59s/it]#015 54%|█████▍    | 92/171 [03:41<03:19,  2.53s/it]#015                                                #015#015 54%|█████▍    | 92/171 [03:41<03:19,  2.53s/it]#015 54%|█████▍    | 93/171 [03:43<03:20,  2.57s/it]#015                                                #015#015 54%|█████▍    | 93/171 [03:43<03:20,  2.57s/it]#015 55%|█████▍    | 94/171 [03:45<03:04,  2.40s/it]#015                                                #015#015 55%|█████▍    | 94/171 [03:45<03:04,  2.40s/it]#015 56%|█████▌    | 95/171 [03:47<02:56,  2.33s/it]#015                                                #015#015 56%|█████▌    | 95/171 [03:47<02:56,  2.33s/it]#015 56%|█████▌    | 96/171 [03:50<02:54,  2.32s/it]#015                                                #015#015 56%|█████▌    | 96/171 [03:50<02:54,  2.32s/it]#015 57%|█████▋    | 97/171 [03:52<02:56,  2.39s/it]#015                                                #015#015 57%|█████▋    | 97/171 [03:52<02:56,  2.39s/it]#015 57%|█████▋    | 98/171 [03:55<03:05,  2.54s/it]#015                                                #015#015 57%|█████▋    | 98/171 [03:55<03:05,  2.54s/it]#015 58%|█████▊    | 99/171 [03:57<02:57,  2.47s/it]#015                                                #015#015 58%|█████▊    | 99/171 [03:57<02:57,  2.47s/it]#015 58%|█████▊    | 100/171 [04:00<02:49,  2.39s/it]#015                                                 #015#015 58%|█████▊    | 100/171 [04:00<02:49,  2.39s/it]#015 59%|█████▉    | 101/171 [04:02<02:38,  2.27s/it]#015                                                 #015#015 59%|█████▉    | 101/171 [04:02<02:38,  2.27s/it]#015 60%|█████▉    | 102/171 [04:04<02:39,  2.31s/it]#015                                      \u001b[0m\n",
      "\u001b[34m{'loss': 0.1814, 'grad_norm': 0.9109023809432983, 'learning_rate': 8.070175438596491e-05, 'epoch': 1.81}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1628, 'grad_norm': 1.1110299825668335, 'learning_rate': 7.953216374269006e-05, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2102, 'grad_norm': 1.1459922790527344, 'learning_rate': 7.836257309941521e-05, 'epoch': 1.85}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1965, 'grad_norm': 1.2940318584442139, 'learning_rate': 7.719298245614036e-05, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1555, 'grad_norm': 0.8029183745384216, 'learning_rate': 7.602339181286549e-05, 'epoch': 1.88}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2085, 'grad_norm': 1.138192892074585, 'learning_rate': 7.485380116959064e-05, 'epoch': 1.9}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1833, 'grad_norm': 0.9841808080673218, 'learning_rate': 7.368421052631579e-05, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1372, 'grad_norm': 0.4892066717147827, 'learning_rate': 7.251461988304094e-05, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1404, 'grad_norm': 1.046491265296936, 'learning_rate': 7.134502923976609e-05, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1521, 'grad_norm': 1.0805065631866455, 'learning_rate': 7.017543859649122e-05, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1401, 'grad_norm': 0.5201672911643982, 'learning_rate': 6.900584795321637e-05, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1029, 'grad_norm': 0.5175055861473083, 'learning_rate': 6.783625730994152e-05, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1676, 'grad_norm': 1.4536373615264893, 'learning_rate': 6.666666666666667e-05, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1067, 'grad_norm': 0.5955309271812439, 'learning_rate': 6.549707602339182e-05, 'epoch': 2.04}\u001b[0m\n",
      "\u001b[34m{'loss': 0.12, 'grad_norm': 0.6343761682510376, 'learning_rate': 6.432748538011695e-05, 'epoch': 2.05}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1487, 'grad_norm': 0.8394286632537842, 'learning_rate': 6.31578947368421e-05, 'epoch': 2.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1485, 'grad_norm': 1.0237839221954346, 'learning_rate': 6.198830409356725e-05, 'epoch': 2.09}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1098, 'grad_norm': 0.5049227476119995, 'learning_rate': 6.0818713450292395e-05, 'epoch': 2.11}\u001b[0m\n",
      "\u001b[34m{'loss': 0.143, 'grad_norm': 0.6351966261863708, 'learning_rate': 5.9649122807017544e-05, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1106, 'grad_norm': 0.6711061000823975, 'learning_rate': 5.847953216374269e-05, 'epoch': 2.14}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1112, 'grad_norm': 0.9857292771339417, 'learning_rate': 5.7309941520467835e-05, 'epoch': 2.16}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1326, 'grad_norm': 0.5811606049537659, 'learning_rate': 5.6140350877192984e-05, 'epoch': 2.18}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1206, 'grad_norm': 0.6596582531929016, 'learning_rate': 5.4970760233918126e-05, 'epoch': 2.19}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1402, 'grad_norm': 1.1134978532791138, 'learning_rate': 5.3801169590643275e-05, 'epoch': 2.21}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1141, 'grad_norm': 0.8898439407348633, 'learning_rate': 5.2631578947368424e-05, 'epoch': 2.23}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1197, 'grad_norm': 0.5411272644996643, 'learning_rate': 5.1461988304093566e-05, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1227, 'grad_norm': 0.640212893486023, 'learning_rate': 5.0292397660818715e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1442, 'grad_norm': 0.7229347229003906, 'learning_rate': 4.912280701754386e-05, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1568, 'grad_norm': 1.07701575756073, 'learning_rate': 4.7953216374269006e-05, 'epoch': 2.3}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1342, 'grad_norm': 0.46701788902282715, 'learning_rate': 4.678362573099415e-05, 'epoch': 2.32}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1704, 'grad_norm': 1.3562941551208496, 'learning_rate': 4.56140350877193e-05, 'epoch': 2.34}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1383, 'grad_norm': 0.5087694525718689, 'learning_rate': 4.4444444444444447e-05, 'epoch': 2.35}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1352, 'grad_norm': 0.5073748826980591, 'learning_rate': 4.327485380116959e-05, 'epoch': 2.37}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1219, 'grad_norm': 0.45434266328811646, 'learning_rate': 4.210526315789474e-05, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1186, 'grad_norm': 0.6930144429206848, 'learning_rate': 4.093567251461988e-05, 'epoch': 2.41}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1083, 'grad_norm': 0.48865818977355957, 'learning_rate': 3.976608187134503e-05, 'epoch': 2.42}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2156, 'grad_norm': 1.8559527397155762, 'learning_rate': 3.859649122807018e-05, 'epoch': 2.44}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1225, 'grad_norm': 0.4524928033351898, 'learning_rate': 3.742690058479532e-05, 'epoch': 2.46}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1078, 'grad_norm': 0.3388880789279938, 'learning_rate': 3.625730994152047e-05, 'epoch': 2.48}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1067, 'grad_norm': 0.4045164883136749, 'learning_rate': 3.508771929824561e-05, 'epoch': 2.5}\u001b[0m\n",
      "\u001b[34m{'loss': 0.13, 'grad_norm': 0.7892025709152222, 'learning_rate': 3.391812865497076e-05, 'epoch': 2.51}\u001b[0m\n",
      "\u001b[34m{'loss': 0.119, 'grad_norm': 0.5817837119102478, 'learning_rate': 3.274853801169591e-05, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.114, 'grad_norm': 0.39472052454948425, 'learning_rate': 3.157894736842105e-05, 'epoch': 2.55}\u001b[0m\n",
      "\u001b[34m{'loss': 0.0928, 'grad_norm': 0.4714561700820923, 'learning_rate': 3.0409356725146197e-05, 'epoch': 2.57}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1503, 'grad_norm': 1.0023547410964966, 'learning_rate': 2.9239766081871346e-05, 'epoch': 2.58}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1699, 'grad_norm': 0.7112419605255127, 'learning_rate': 2.8070175438596492e-05, 'epoch': 2.6}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1921, 'grad_norm': 0.6974067687988281, 'learning_rate': 2.6900584795321637e-05, 'epoch': 2.62}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1527, 'grad_norm': 0.7341486215591431, 'learning_rate': 2.5730994152046783e-05, 'epoch': 2.64}\u001b[0m\n",
      "\u001b[34m{'loss': 0.0885, 'grad_norm': 0.31031492352485657, 'learning_rate': 2.456140350877193e-05, 'epoch': 2.65}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1102, 'grad_norm': 0.34067341685295105, 'learning_rate': 2.3391812865497074e-05, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1046, 'grad_norm': 0.34311649203300476, 'learning_rate': 2.2222222222222223e-05, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1207, 'grad_norm': 0.3587213456630707, 'learning_rate': 2.105263157894737e-05, 'epoch': 2.71}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1208, 'grad_norm': 0.36165452003479004, 'learning_rate': 1.9883040935672515e-05, 'epoch': 2.73}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1035, 'grad_norm': 0.30963191390037537, 'learning_rate': 1.871345029239766e-05, 'epoch': 2.74}\u001b[0m\n",
      "\u001b[34m{'loss': 0.0987, 'grad_norm': 0.3222021460533142, 'learning_rate': 1.7543859649122806e-05, 'epoch': 2.76}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1383, 'grad_norm': 0.519044816493988, 'learning_rate': 1.6374269005847955e-05, 'epoch': 2.78}\u001b[0m\n",
      "\u001b[34m{'loss': 0.0856, 'grad_norm': 0.31553229689598083, 'learning_rate': 1.5204678362573099e-05, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.0907, 'grad_norm': 0.3468725383281708, 'learning_rate': 1.4035087719298246e-05, 'epoch': 2.81}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1238, 'grad_norm': 0.40495726466178894, 'learning_rate': 1.2865497076023392e-05, 'epoch': 2.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.109, 'grad_norm': 0.3268435597419739, 'learning_rate': 1.1695906432748537e-05, 'epoch': 2.85}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1212, 'grad_norm': 0.45231011509895325, 'learning_rate': 1.0526315789473684e-05, 'epoch': 2.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1107, 'grad_norm': 0.32671216130256653, 'learning_rate': 9.35672514619883e-06, 'epoch': 2.88}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2117, 'grad_norm': 0.9193713068962097, 'learning_rate': 8.187134502923977e-06, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m{'loss': 0.0964, 'grad_norm': 0.32005834579467773, 'learning_rate': 7.017543859649123e-06, 'epoch': 2.92}\u001b[0m\n",
      "\u001b[34m{'loss': 0.111, 'grad_norm': 0.3464086651802063, 'learning_rate': 5.8479532163742686e-06, 'epoch': 2.94}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1391, 'grad_norm': 0.5274222493171692, 'learning_rate': 4.678362573099415e-06, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1228, 'grad_norm': 0.3800055980682373, 'learning_rate': 3.5087719298245615e-06, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1059, 'grad_norm': 0.3205595016479492, 'learning_rate': 2.3391812865497075e-06, 'epoch': 2.99}\u001b[0m\n",
      "\u001b[34m{'loss': 0.1151, 'grad_norm': 0.5027665495872498, 'learning_rate': 1.1695906432748538e-06, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 412.0988, 'train_samples_per_second': 6.552, 'train_steps_per_second': 0.415, 'train_loss': 0.5617773197809158, 'epoch': 3.0}\n",
      "           #015#015 60%|█████▉    | 102/171 [04:04<02:39,  2.31s/it]#015 60%|██████    | 103/171 [04:07<02:40,  2.35s/it]#015                                                 #015#015 60%|██████    | 103/171 [04:07<02:40,  2.35s/it]#015 61%|██████    | 104/171 [04:09<02:36,  2.34s/it]#015                                                 #015#015 61%|██████    | 104/171 [04:09<02:36,  2.34s/it]#015 61%|██████▏   | 105/171 [04:11<02:37,  2.39s/it]#015                                                 #015#015 61%|██████▏   | 105/171 [04:11<02:37,  2.39s/it]#015 62%|██████▏   | 106/171 [04:13<02:29,  2.30s/it]#015                                                 #015#015 62%|██████▏   | 106/171 [04:13<02:29,  2.30s/it]#015 63%|██████▎   | 107/171 [04:16<02:35,  2.43s/it]#015                                                 #015#015 63%|██████▎   | 107/171 [04:16<02:35,  2.43s/it]#015 63%|██████▎   | 108/171 [04:19<02:36,  2.49s/it]#015                                                 #015#015 63%|██████▎   | 108/171 [04:19<02:36,  2.49s/it]#015 64%|██████▎   | 109/171 [04:22<02:49,  2.73s/it]#015                                                 #015#015 64%|██████▎   | 109/171 [04:22<02:49,  2.73s/it]#015 64%|██████▍   | 110/171 [04:24<02:40,  2.63s/it]#015                                                 #015#015 64%|██████▍   | 110/171 [04:24<02:40,  2.63s/it]#015 65%|██████▍   | 111/171 [04:27<02:36,  2.61s/it]#015                                                 #015#015 65%|██████▍   | 111/171 [04:27<02:36,  2.61s/it]#015 65%|██████▌   | 112/171 [04:29<02:23,  2.43s/it]#015                                                 #015#015 65%|██████▌   | 112/171 [04:29<02:23,  2.43s/it]#015 66%|██████▌   | 113/171 [04:32<02:21,  2.44s/it]#015                                                 #015#015 66%|██████▌   | 113/171 [04:32<02:21,  2.44s/it]#015 67%|██████▋   | 114/171 [04:33<02:05,  2.20s/it]#015                                                 #015#015 67%|██████▋   | 114/171 [04:33<02:05,  2.20s/it]#015 67%|██████▋   | 115/171 [04:35<02:02,  2.19s/it]#015                                                 #015#015 67%|██████▋   | 115/171 [04:35<02:02,  2.19s/it]#015 68%|██████▊   | 116/171 [04:38<02:03,  2.25s/it]#015                                                 #015#015 68%|██████▊   | 116/171 [04:38<02:03,  2.25s/it]#015 68%|██████▊   | 117/171 [04:40<02:05,  2.32s/it]#015                                                 #015#015 68%|██████▊   | 117/171 [04:40<02:05,  2.32s/it]#015 69%|██████▉   | 118/171 [04:43<02:06,  2.39s/it]#015                                                 #015#015 69%|██████▉   | 118/171 [04:43<02:06,  2.39s/it]#015 70%|██████▉   | 119/171 [04:45<02:08,  2.47s/it]#015                                                 #015#015 70%|██████▉   | 119/171 [04:45<02:08,  2.47s/it]#015 70%|███████   | 120/171 [04:48<02:05,  2.47s/it]#015                                                 #015#015 70%|███████   | 120/171 [04:48<02:05,  2.47s/it]#015 71%|███████   | 121/171 [04:50<02:03,  2.46s/it]#015                                                 #015#015 71%|███████   | 121/171 [04:50<02:03,  2.46s/it]#015 71%|███████▏  | 122/171 [04:53<02:08,  2.63s/it]#015                                                 #015#015 71%|███████▏  | 122/171 [04:53<02:08,  2.63s/it]#015 72%|███████▏  | 123/171 [04:56<02:03,  2.57s/it]#015                                                 #015#015 72%|███████▏  | 123/171 [04:56<02:03,  2.57s/it]#015 73%|███████▎  | 124/171 [04:58<01:53,  2.40s/it]#015                                                 #015#015 73%|███████▎  | 124/171 [04:58<01:53,  2.40s/it]#015 73%|███████▎  | 125/171 [05:00<01:50,  2.41s/it]#015                                                 #015#015 73%|███████▎  | 125/171 [05:00<01:50,  2.41s/it]#015 74%|███████▎  | 126/171 [05:02<01:45,  2.34s/it]#015                                                 #015#015 74%|███████▎  | 126/171 [05:02<01:45,  2.34s/it]#015 74%|███████▍  | 127/171 [05:05<01:46,  2.41s/it]#015                                                 #015#015 74%|███████▍  | 127/171 [05:05<01:46,  2.41s/it]#015 75%|███████▍  | 128/171 [05:08<01:45,  2.46s/it]#015                                                 #015#015 75%|███████▍  | 128/171 [05:08<01:45,  2.46s/it]#015 75%|███████▌  | 129/171 [05:10<01:43,  2.46s/it]#015                                                 #015#015 75%|███████▌  | 129/171 [05:10<01:43,  2.46s/it]#015 76%|███████▌  | 130/171 [05:12<01:39,  2.42s/it]#015                                                 #015#015 76%|███████▌  | 130/171 [05:12<01:39,  2.42s/it]#015 77%|███████▋  | 131/171 [05:15<01:36,  2.41s/it]#015                                                 #015#015 77%|███████▋  | 131/171 [05:15<01:36,  2.41s/it]#015 77%|███████▋  | 132/171 [05:17<01:31,  2.35s/it]#015                                                 #015#015 77%|███████▋  | 132/171 [05:17<01:31,  2.35s/it]#015 78%|███████▊  | 133/171 [05:19<01:28,  2.33s/it]#015                                                 #015#015 78%|███████▊  | 133/171 [05:19<01:28,  2.33s/it]#015 78%|███████▊  | 134/171 [05:22<01:27,  2.35s/it]#015                                                 #015#015 78%|███████▊  | 134/171 [05:22<01:27,  2.35s/it]#015 79%|███████▉  | 135/171 [05:24<01:25,  2.37s/it]#015                                                 #015#015 79%|███████▉  | 135/171 [05:24<01:25,  2.37s/it]#015 80%|███████▉  | 136/171 [05:26<01:22,  2.36s/it]#015                                                 #015#015 80%|███████▉  | 136/171 [05:26<01:22,  2.36s/it]#015 80%|████████  | 137/171 [05:29<01:19,  2.33s/it]#015                                                 #015#015 80%|████████  | 137/171 [05:29<01:19,  2.33s/it]#015 81%|████████  | 138/171 [05:31<01:15,  2.29s/it]#015                                                 #015#015 81%|████████  | 138/171 [05:31<01:15,  2.29s/it]#015 81%|████████▏ | 139/171 [05:34<01:17,  2.42s/it]#015                                                 #015#015 81%|████████▏ | 139/171 [05:34<01:17,  2.42s/it]#015 82%|████████▏ | 140/171 [05:36<01:13,  2.37s/it]#015                                                 #015#015 82%|████████▏ | 140/171 [05:36<01:13,  2.37s/it]#015 82%|████████▏ | 141/171 [05:39<01:15,  2.52s/it]#015                                                 #015#015 82%|████████▏ | 141/171 [05:39<01:15,  2.52s/it]#015 83%|████████▎ | 142/171 [05:41<01:12,  2.50s/it]#015                                                 #015#015 83%|████████▎ | 142/171 [05:41<01:12,  2.50s/it]#015 84%|████████▎ | 143/171 [05:44<01:09,  2.48s/it]#015                                                 #015#015 84%|████████▎ | 143/171 [05:44<01:09,  2.48s/it]#015 84%|████████▍ | 144/171 [05:46<01:09,  2.56s/it]#015                                                 #015#015 84%|████████▍ | 144/171 [05:46<01:09,  2.56s/it]#015 85%|████████▍ | 145/171 [05:49<01:07,  2.61s/it]#015                                                 #015#015 85%|████████▍ | 145/171 [05:49<01:07,  2.61s/it]#015 85%|████████▌ | 146/171 [05:52<01:10,  2.81s/it]#015                                                 #015#015 85%|████████▌ | 146/171 [05:52<01:10,  2.81s/it]#015 86%|████████▌ | 147/171 [05:55<01:04,  2.68s/it]#015                                                 #015#015 86%|████████▌ | 147/171 [05:55<01:04,  2.68s/it]#015 87%|████████▋ | 148/171 [05:57<00:58,  2.56s/it]#015                                                 #015#015 87%|████████▋ | 148/171 [05:57<00:58,  2.56s/it]#015 87%|████████▋ | 149/171 [05:59<00:55,  2.51s/it]#015                                                 #015#015 87%|████████▋ | 149/171 [05:59<00:55,  2.51s/it]#015 88%|████████▊ | 150/171 [06:01<00:49,  2.36s/it]#015                                                 #015#015 88%|████████▊ | 150/171 [06:01<00:49,  2.36s/it]#015 88%|████████▊ | 151/171 [06:04<00:50,  2.52s/it]#015                                                 #015#015 88%|████████▊ | 151/171 [06:04<00:50,  2.52s/it]#015 89%|████████▉ | 152/171 [06:06<00:46,  2.43s/it]#015                                                 #015#015 89%|████████▉ | 152/171 [06:06<00:46,  2.43s/it]#015 89%|████████▉ | 153/171 [06:09<00:44,  2.46s/it]#015                                                 #015#015 89%|████████▉ | 153/171 [06:09<00:44,  2.46s/it]#015 90%|█████████ | 154/171 [06:11<00:40,  2.37s/it]#015                                                 #015#015 90%|█████████ | 154/171 [06:11<00:40,  2.37s/it]#015 91%|█████████ | 155/171 [06:13<00:36,  2.31s/it]#015                                                 #015#015 91%|█████████ | 155/171 [06:13<00:36,  2.31s/it]#015 91%|█████████ | 156/171 [06:16<00:34,  2.32s/it]#015                                                 #015#015 91%|█████████ | 156/171 [06:16<00:34,  2.32s/it]#015 92%|█████████▏| 157/171 [06:18<00:33,  2.38s/it]#015                                                 #015#015 92%|█████████▏| 157/171 [06:18<00:33,  2.38s/it]#015 92%|█████████▏| 158/171 [06:20<00:29,  2.27s/it]#015                                                 #015#015 92%|█████████▏| 158/171 [06:20<00:29,  2.27s/it]#015 93%|█████████▎| 159/171 [06:23<00:28,  2.36s/it]#015                                                 #015#015 93%|█████████▎| 159/171 [06:23<00:28,  2.36s/it]#015 94%|█████████▎| 160/171 [06:25<00:26,  2.42s/it]#015                                                 #015#015 94%|█████████▎| 160/171 [06:25<00:26,  2.42s/it]#015 94%|█████████▍| 161/171 [06:27<00:23,  2.35s/it]#015                                                 #015#015 94%|█████████▍| 161/171 [06:27<00:23,  2.35s/it]#015 95%|█████████▍| 162/171 [06:30<00:21,  2.41s/it]#015                                                 #015#015 95%|█████████▍| 162/171 [06:30<00:21,  2.41s/it]#015 95%|█████████▌| 163/171 [06:32<00:18,  2.35s/it]#015                                                 #015#015 95%|█████████▌| 163/171 [06:32<00:18,  2.35s/it]#015 96%|█████████▌| 164/171 [06:34<00:15,  2.24s/it]#015                                                 #015#015 96%|█████████▌| 164/171 [06:34<00:15,  2.24s/it]#015 96%|█████████▋| 165/171 [06:36<00:13,  2.22s/it]#015                                                 #015#015 96%|█████████▋| 165/171 [06:36<00:13,  2.22s/it]#015 97%|█████████▋| 166/171 [06:39<00:11,  2.38s/it]#015                                                 #015#015 97%|█████████▋| 166/171 [06:39<00:11,  2.38s/it]#015 98%|█████████▊| 167/171 [06:42<00:09,  2.43s/it]#015                                                 #015#015 98%|█████████▊| 167/171 [06:42<00:09,  2.43s/it]#015 98%|█████████▊| 168/171 [06:44<00:06,  2.29s/it]#015                                                 #015#015 98%|█████████▊| 168/171 [06:44<00:06,  2.29s/it]#015 99%|█████████▉| 169/171 [06:46<00:04,  2.21s/it]#015                                                 #015#015 99%|█████████▉| 169/171 [06:46<00:04,  2.21s/it]#015 99%|█████████▉| 170/171 [06:48<00:02,  2.31s/it]#015                                                 #015#015 99%|█████████▉| 170/171 [06:48<00:02,  2.31s/it]#015100%|██████████| 171/171 [06:50<00:00,  1.99s/it]#015                                                 #015#015100%|██████████| 171/171 [06:50<00:00,  1.99s/it]#015                                                 #015#015100%|██████████| 171/171 [06:50<00:00,  1.99s/it]#015100%|██████████| 171/171 [06:50<00:00,  2.40s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]#015Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.64s/it]#015Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.69s/it]#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.69s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.58s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.99s/it]\u001b[0m\n",
      "\n",
      "2025-08-26 03:48:03 Uploading - Uploading generated training model\u001b[34m2025-08-26 03:47:56,577 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/results\u001b[0m\n",
      "\u001b[34m2025-08-26 03:47:56,577 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/results\u001b[0m\n",
      "\u001b[34m2025-08-26 03:47:56,577 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/results\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:137:502 [1] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:137:502 [1] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:137:222 [1] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:137:502 [1] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:139:503 [3] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:139:503 [3] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:139:503 [3] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:139:220 [3] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:138:504 [2] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:138:504 [2] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:138:504 [2] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:138:221 [2] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:137:502 [1] NCCL INFO comm 0x55e1c00d6ca0 rank 1 nranks 4 cudaDev 1 busId 1c0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:139:503 [3] NCCL INFO comm 0x56053bc51920 rank 3 nranks 4 cudaDev 3 busId 1e0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:138:504 [2] NCCL INFO comm 0x559a7d9a1a20 rank 2 nranks 4 cudaDev 2 busId 1d0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m2025-08-26 03:47:57,899 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-278313627171/train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792/results\u001b[0m\n",
      "\u001b[34m[rank0]:[W826 03:47:58.470496158 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:136:509 [0] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:136:509 [0] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:136:219 [0] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:136:509 [0] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-227-86:136:509 [0] NCCL INFO comm 0x559c36723e70 rank 0 nranks 4 cudaDev 0 busId 1b0 - Abort COMPLETE\u001b[0m\n",
      "\n",
      "2025-08-26 03:49:06 Completed - Training job completed\n",
      "Training seconds: 913\n",
      "Billable seconds: 913\n"
     ]
    }
   ],
   "source": [
    "train_fn(\n",
    "    model_id,\n",
    "    train_ds=train_dataset,\n",
    "    test_ds=test_dataset,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    num_train_epochs=3,\n",
    "    merge_weights=True,\n",
    "    token=os.environ.get(\"HF_TOKEN\", None) # Change None to your HF_TOKEN in case you don't use .env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Fine-Tuned model\n",
    "\n",
    "Note: Run `train_fn` with `merge_weights=True` for merging the trained adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:08.515277Z",
     "start_time": "2023-11-20T18:41:08.503555Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model_id = \"aisingapore/Llama-SEA-LION-v3.5-8B-R\"\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    matching_jobs = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        # Prepare the search parameters\n",
    "        search_params = {\n",
    "            'Resource': 'TrainingJob',\n",
    "            'SearchExpression': {\n",
    "                'Filters': [\n",
    "                    {\n",
    "                        'Name': 'TrainingJobName',\n",
    "                        'Operator': 'Contains',\n",
    "                        'Value': job_name_prefix\n",
    "                    },\n",
    "                    {\n",
    "                        'Name': 'TrainingJobStatus',\n",
    "                        'Operator': 'Equals',\n",
    "                        'Value': \"Completed\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            'SortBy': 'CreationTime',\n",
    "            'SortOrder': 'Descending',\n",
    "            'MaxResults': 100\n",
    "        }\n",
    "\n",
    "        # Add NextToken if we have one\n",
    "        if next_token:\n",
    "            search_params['NextToken'] = next_token\n",
    "\n",
    "        # Make the search request\n",
    "        search_response = sagemaker_client.search(**search_params)\n",
    "\n",
    "        # Filter and add matching jobs\n",
    "        matching_jobs.extend([\n",
    "            job['TrainingJob']['TrainingJobName'] \n",
    "            for job in search_response['Results']\n",
    "            if job['TrainingJob']['TrainingJobName'].startswith(job_name_prefix)\n",
    "        ])\n",
    "\n",
    "        # Check if we have more results to fetch\n",
    "        next_token = search_response.get('NextToken')\n",
    "        if not next_token or matching_jobs:  # Stop if we found at least one match or no more results\n",
    "            break\n",
    "\n",
    "    if not matching_jobs:\n",
    "        raise ValueError(f\"No completed training jobs found starting with prefix '{job_name_prefix}'\")\n",
    "\n",
    "    return matching_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train-Llama-SEA-LION-v3-5-8B-R-2025-08-26-03-31-30-792'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.8xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook does not work on some earlier versions of the HuggingFace TGI container, such as version 2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:11.162811Z",
     "start_time": "2023-11-20T18:41:10.787936Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py311\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.6.0-tgi3.2.0-gpu-py311-cu124-ubuntu22.04'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri = get_huggingface_llm_image_uri(\n",
    "    \"huggingface\",\n",
    "    version=\"3.2.0\" # \"2.2.0\"  # Update from 2.2.0 to a newer version\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Image URI for training job:\n",
    "`763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.5.1-gpu-py311-cu124-ubuntu22.04-sagemaker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:12.433399Z",
     "start_time": "2023-11-20T18:41:11.963091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.Model.EnableNetworkIsolation\n"
     ]
    }
   ],
   "source": [
    "if default_prefix:\n",
    "    model_data = f\"s3://{bucket_name}/{default_prefix}/{job_name}/{job_name}/output/model.tar.gz\"\n",
    "else:\n",
    "    model_data = f\"s3://{bucket_name}/{job_name}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "        'QUANTIZE': 'bitsandbytes',\n",
    "        'MAX_INPUT_LENGTH': '4096',\n",
    "        'MAX_TOTAL_TOKENS': '8192'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the following fails, you may wish to:\n",
    "- check the troubleshooting guide: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html#sagemaker-python-sdk-troubleshooting-create-endpoint\n",
    "- check the Cloudwatch logs: `/aws/sagemaker/Endpoints/{endpoint_name}` (for example, it may look something like this: `/aws/sagemaker/Endpoints/huggingface-pytorch-tgi-inference-2025-xx-xx-xx-xx-xx-xxx`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2025-08-26-05-09-13-292\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2025-08-26-05-09-14-868\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2025-08-26-05-09-14-868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint: huggingface-pytorch-tgi-inference-2025-08-26-05-09-14-868\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Automatically retrieve the first endpoint (if this is your only endpoint)\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "response = sagemaker_client.list_endpoints()\n",
    "endpoint_names = [ endpoint['EndpointName'] for endpoint in response['Endpoints'] ]\n",
    "if len(endpoint_names):\n",
    "    endpoint_name = endpoint_names[0]\n",
    "    print(f'Using endpoint: {endpoint_name}')\n",
    "\n",
    "# Option 2: Set the endpoint name manually (Uncomment below to use Option 2)\n",
    "# endpoint_name = \"gemma-3-27b-it-... (replace with your enpoint name)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'predictor' not in locals() and 'predictor' not in globals():\n",
    "    print(\"Create predictor\")\n",
    "    predictor = HuggingFacePredictor(\n",
    "        endpoint_name=endpoint_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{{question}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Mary'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = base_prompt.format(question=\"What statue is in front of the Notre Dame building?\")\n",
    "\n",
    "predictor.predict({\n",
    "\t\"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"stop\": ['<|eot_id|>', '<|end_of_text|>']\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_sealion(prompt: str, print_response=True, **kwargs):\n",
    "    # Create payload\n",
    "    parameters = {\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"stop\": ['<|eot_id|>', '<|end_of_text|>']\n",
    "    }\n",
    "    for k in kwargs:\n",
    "        if k in ['max_new_tokens', 'temperature', 'top_p' ]:\n",
    "            parameters[k] = kwargs[k]\n",
    "    payload = {\n",
    "    \t\"inputs\": base_prompt.format(question=prompt),\n",
    "        \"parameters\": parameters\n",
    "    }\n",
    "\n",
    "    # Invoke the model\n",
    "    response = predictor.predict(payload)\n",
    "    if print_response:\n",
    "        print(response[0]['generated_text'])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PROMPTS = [\n",
    "    \"\"\"Terjemahkan teks berikut ini ke dalam Bahasa Inggris. Teks: Anak laki-laki ini, yang secara teknis tidak diijinkan untuk memiliki akun situs ini untuk tiga tahun mendatang,menemukan sebuah bug (kesalahan akibat ketidaksempurnaan desain) yang memungkinkan dia menghapus komentar yang dibuat oleh pengguna lain. Masalah ini dengan “cepat” diperbaiki setelah ditemukan, demikian keterangan Facebook, perusahaan media sosial yang memiliki Instagram. Jani kemudian dibayar - yang membuat dia sebagai anak yang termuda yang pernah menerima hadiah atas penemuan bug ini. Setelah menemukan kekurangan itu pada Februari, dia mengirim email ke Facebook. Beli sepeda dan peralatan sepak bola Sejumlah ahli teknik keamanan di perusahaan itu telah membuat akun uji coba kepada Jani untuk membuktikan teorinya - dan dia dapat melakukannya. Anak laki-laki ini, dari Helsinki, mengatakan kepada koran Finlandia Iltalehti, dia berencana untuk menggunakan uang itu untuk membeli sepeda baru, peralatan sepak bola dan komputer untuk saudara laki-lakinya. Facebook mengatakan kepada BBC, telah membayar $4.3 juta sebagai hadiah bagi yang menemukan bug sejak 2011. Banyak perusahaan menawarkan sebuah insentif keuangan bagi profesional keamanan - dan anak-anak muda, yang menyampaikan kekurangan itu kepada perusahaan, dibandingkan menjualnya ke pasar gelap. Terjemahan:\"\"\",\n",
    "    \"\"\"Apa sentimen dari kalimat berikut ini? Kalimat: Buku ini sangat membosankan. Jawaban:\"\"\",\n",
    "    \"\"\"Anda akan diberikan sebuah teks dan pertanyaan. Jawablah pertanyaan tersebut berdasarkan teks yang tersedia. > Teks: “Isyana lahir di Bandung pada 2 Mei 1993. Dia menghabiskan masa kecilnya di berbagai lokasi, karena orang tuanya bekerja & melanjutkan studi mereka di Belgia. Namun, pada usia 7 tahun keluarganya pindah ke Bandung, Indonesia. Isyana adalah putri bungsu dari pasangan Luana Marpanda, seorang guru musik, dan Sapta Dwikardana, Ph.D seorang dosen dan terapis (grafologis). Ia memiliki kakak perempuan bernama Rara Sekar Larasati, yang juga merupakan vokalis band bernama Banda Neira. Dibesarkan dalam keluarga pendidik, Isyana diperkenalkan ke dunia musik pada usia 4 tahun oleh ibunya. Isyana telah menguasai sejumlah instrumen. Termasuk piano, electone, flute, biola, dan saksofon.” > Pertanyaan: Siapa nama orang tua Isyana?\"\"\",\n",
    "    \"\"\"Sebutkan persamaan dan perbedaan antara gado-gado, ketoprak dan karedok\"\"\",\n",
    "    \"\"\"Jelaskan budaya Indonesia menyapa orang yang lebih tua?\"\"\",\n",
    "    \"\"\"Jelaskan budaya pulang kampung ketika lebaran?\"\"\",\n",
    "    \"\"\"Sebutkan berbagai jenis kopi dan karakteristik rasanya yang berasal dari Indonesia\"\"\"   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Prompt: Terjemahkan teks berikut ini ke dalam Bahasa Inggris. Teks: Anak laki-laki ini, yang secara teknis tidak diijinkan untuk memiliki akun situs ini untuk tiga tahun mendatang,menemukan sebuah bug (kesalahan akibat ketidaksempurnaan desain) yang memungkinkan dia menghapus komentar yang dibuat oleh pengguna lain. Masalah ini dengan “cepat” diperbaiki setelah ditemukan, demikian keterangan Facebook, perusahaan media sosial yang memiliki Instagram. Jani kemudian dibayar - yang membuat dia sebagai anak yang termuda yang pernah menerima hadiah atas penemuan bug ini. Setelah menemukan kekurangan itu pada Februari, dia mengirim email ke Facebook. Beli sepeda dan peralatan sepak bola Sejumlah ahli teknik keamanan di perusahaan itu telah membuat akun uji coba kepada Jani untuk membuktikan teorinya - dan dia dapat melakukannya. Anak laki-laki ini, dari Helsinki, mengatakan kepada koran Finlandia Iltalehti, dia berencana untuk menggunakan uang itu untuk membeli sepeda baru, peralatan sepak bola dan komputer untuk saudara laki-lakinya. Facebook mengatakan kepada BBC, telah membayar $4.3 juta sebagai hadiah bagi yang menemukan bug sejak 2011. Banyak perusahaan menawarkan sebuah insentif keuangan bagi profesional keamanan - dan anak-anak muda, yang menyampaikan kekurangan itu kepada perusahaan, dibandingkan menjualnya ke pasar gelap. Terjemahan: #####\n",
      "##### Response #####\n",
      "This boy, who is technically not allowed to have an account on this site for the next three years, found a bug (a flaw in the design) that allowed him to delete comments made by other users. This problem was quickly fixed after being found, according to Facebook, the social media company that owns Instagram. Jani was then rewarded – making him the youngest person to have ever received a reward for finding a bug. After finding the flaw in February, he sent an email to Facebook. A number of IT security experts at the company made trial accounts for Jani to prove his theory – and he was able to do so. The boy from Helsinki told Finnish newspaper Iltalehti that he plans to use the money to buy himself a new bicycle, football equipment and a computer for his brother. Facebook told BBC News it has paid $4.3 million as a reward for finding bugs since 2011. Many companies offer financial incentives for security professionals – and young people who tell the company of the flaw, rather than selling it on the black market.\n",
      "\n",
      "##### Prompt: Apa sentimen dari kalimat berikut ini? Kalimat: Buku ini sangat membosankan. Jawaban: #####\n",
      "##### Response #####\n",
      "negatif\n",
      "\n",
      "##### Prompt: Anda akan diberikan sebuah teks dan pertanyaan. Jawablah pertanyaan tersebut berdasarkan teks yang tersedia. > Teks: “Isyana lahir di Bandung pada 2 Mei 1993. Dia menghabiskan masa kecilnya di berbagai lokasi, karena orang tuanya bekerja & melanjutkan studi mereka di Belgia. Namun, pada usia 7 tahun keluarganya pindah ke Bandung, Indonesia. Isyana adalah putri bungsu dari pasangan Luana Marpanda, seorang guru musik, dan Sapta Dwikardana, Ph.D seorang dosen dan terapis (grafologis). Ia memiliki kakak perempuan bernama Rara Sekar Larasati, yang juga merupakan vokalis band bernama Banda Neira. Dibesarkan dalam keluarga pendidik, Isyana diperkenalkan ke dunia musik pada usia 4 tahun oleh ibunya. Isyana telah menguasai sejumlah instrumen. Termasuk piano, electone, flute, biola, dan saksofon.” > Pertanyaan: Siapa nama orang tua Isyana? #####\n",
      "##### Response #####\n",
      "Luana Marpanda dan Sapta Dwikardana\n",
      "\n",
      "##### Prompt: Sebutkan persamaan dan perbedaan antara gado-gado, ketoprak dan karedok #####\n",
      "##### Response #####\n",
      "assistantPersamaan antara gado-gado, ketoprak, dan karedok adalah bahan utamanya yang sama yaitu sayuran, tahu, tempe, dan bumbu kacang. Keduanya juga merupakan makanan khas dari Jawa Barat, Indonesia. Perbedaan utama terletak pada cara penyajiannya dan bahan tambahan yang digunakan. Gado-gado biasanya disajikan dengan nasi, ketoprak disajikan dengan lontong, dan karedok disajikan dengan sayuran mentah.  Bahan tambahan yang digunakan juga berbeda, seperti tahu goreng pada gado-gado, tahu dan tempe mendoan pada ketoprak, dan tahu dan tempe goreng pada karedok.  Apakah Anda ingin mengetahui lebih lanjut mengenai sejarah makanan-makanan ini? Atau mungkin resepnya?\n",
      "\n",
      "##### Prompt: Jelaskan budaya Indonesia menyapa orang yang lebih tua? #####\n",
      "##### Response #####\n",
      "Budaya Indonesia memiliki tradisi yang kuat dalam menghormati orang yang lebih tua. Berikut beberapa cara umum untuk menyapa orang yang lebih tua di Indonesia:1. \"Bapak\" (untuk laki-laki) dan \"Ibu\" (untuk perempuan) - digunakan untuk orang yang dianggap sebagai orang tua, guru, atau atasan.2. \"Kakak\" (untuk laki-laki) dan \"Kakak\" (untuk perempuan) - digunakan untuk saudara laki-laki atau perempuan yang lebih tua.3. \"Mas\" (untuk laki-laki) dan \"Mbak\" (untuk perempuan) - digunakan untuk saudara laki-laki atau perempuan yang sedikit lebih tua dari diri sendiri.4. \"Pak\" (untuk laki-laki) dan \"Bu\" (untuk perempuan) - digunakan untuk orang yang lebih tua yang bukan anggota keluarga atau guru.5. \"Nak\" (untuk laki-laki) dan \"Nak\" (untuk perempuan) - digunakan untuk anak-anak yang lebih muda.6. \"Kakak Tiri\" (untuk laki-laki) dan \"Kakak Tiri\" (untuk perempuan) - digunakan untuk saud\n",
      "\n",
      "##### Prompt: Jelaskan budaya pulang kampung ketika lebaran? #####\n",
      "##### Response #####\n",
      "Budaya pulang kampung ketika lebaran adalah tradisi yang sangat penting bagi masyarakat Indonesia, terutama bagi mereka yang bekerja di kota-kota besar. Lebaran, atau Idul Fitri, adalah momen penting dalam Islam yang menandai akhir dari bulan Ramadhan, bulan puasa. Saat ini, banyak orang kembali ke kampung halaman untuk merayakan bersama keluarga dan merasakan suasana Lebaran yang sesungguhnya.  Berikut adalah beberapa aspek penting dari tradisi ini:1.  Perjalanan Pulang:  Banyak orang bepergian dengan berbagai cara, mulai dari transportasi umum seperti kereta api dan bus, hingga mobil pribadi.  Perjalanan ini seringkali ramai dan memakan waktu lama, terutama karena banyak orang melakukan perjalanan sekaligus.2.  Persiapan Rumah:  Rumah-rumah biasanya didekorasi dengan lampu-lampu dan hiasan lainnya.  Makanan tradisional seperti ketupat, opor ayam, dan rendang sering dimasak untuk menyambut tamu.  Selain itu, kue-kue tradisional seperti kue lapis, kue putu, dan nastar juga dibuat untuk disaj\n",
      "\n",
      "##### Prompt: Sebutkan berbagai jenis kopi dan karakteristik rasanya yang berasal dari Indonesia #####\n",
      "##### Response #####\n",
      "assistantKopi Indonesia dikenal dengan beragam jenis dan karakteristik rasa yang khas. Berikut beberapa jenis kopi yang berasal dari Indonesia beserta ciri khasnya:\n",
      "\n",
      "1. Kopi Arabika\n",
      "- Ditanam di dataran tinggi, terutama di Jawa, Sumatera, Sulawesi, dan Bali\n",
      "- Rasa: Lembut, sedikit manis, dengan aroma yang harum dan sedikit asam\n",
      "- Tingkat keasaman: Sedang\n",
      "- Kandungan kafein: Sedang\n",
      "- Contoh daerah penghasil: Gayo (Aceh), Kintamani (Bali), Toraja (Sulawesi), Kediri (Jawa Timur)\n",
      "\n",
      "2. Kopi Robusta\n",
      "- Ditanam di dataran rendah, terutama di Sumatera, Jawa, dan Sulawesi\n",
      "- Rasa: Kuat, pahit, dengan aroma yang kuat dan sedikit manis\n",
      "- Tingkat keasaman: Rendah\n",
      "- Kandungan kafein: Tinggi\n",
      "- Contoh daerah penghasil: Lampung, Jember (Jawa Timur), Flores (Nusa Tenggara Timur)\n",
      "\n",
      "3. Kopi Liberika\n",
      "- Ditanam di daerah dataran tinggi, terutama di Sulawesi dan Sumatera\n",
      "-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in SAMPLE_PROMPTS:\n",
    "    print(f\"##### Prompt: {prompt} #####\")\n",
    "    print(f\"##### Response #####\")\n",
    "    _ = invoke_sealion(prompt, max_tokens=1000, temperature=0.1, top_p=0.9)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:48:55.153276Z",
     "start_time": "2023-11-20T18:48:54.165351Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-tgi-inference-2025-08-26-05-09-13-292\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-tgi-inference-2025-08-26-05-09-14-868\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-tgi-inference-2025-08-26-05-09-14-868\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert Llama-SEA-LION-v3.5-8B-R-qlora-ddp-remote-decorator_qa.ipynb --to html"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
